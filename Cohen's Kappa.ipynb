{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuition\n",
    "\n",
    "Kappa or Cohenâ€™s Kappa is like classification accuracy, except that it is normalized at the baseline of random chance on your dataset: It basically tells you how much better your classifier is performing over the performance of a classifier that simply guesses at random according to the frequency of each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a multi class confusion matrix between actual and predicted values\n",
    "\n",
    "Warning: This is a counter example to the wrong usage of Quadratic Weighted Kappa. We shall see why soon.\n",
    "\n",
    "First, an N x N confusion matrix **C** is constructed, such that $\\text{C}_{i,j}$ is the entry that corresponds to the **number of animal i (actual) that received a predicted value j**. For example, in the example below, the matrix $C_{2,1}$ is 4, it means that the number of animal cat that received a predicted value of bird is 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = pd.Series(['cat',  'cat', 'dog', 'cat',   'cat',  'cat', 'pig',  'pig', 'hen', 'pig'], name = 'Actual')\n",
    "preds   = pd.Series(['bird', 'hen', 'pig','bird',  'bird', 'bird', 'pig', 'pig', 'hen', 'pig'], name = 'Predicted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [4, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 3]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(actuals, preds); \n",
    "\n",
    "C\n",
    "\n",
    "#print(metrics.classification_report(actuals,preds, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above matrix is a **multi class confusion matrix**. To make it clearer I will create one with labels below. As an example, for the 2nd row, we predicted 4 cats to be birds, and 1 cat to be predicted as hen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>hen</th>\n",
       "      <th>pig</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual/predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bird</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hen</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pig</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  bird  cat  dog  hen  pig\n",
       "actual/predicted                          \n",
       "bird                 0    0    0    0    0\n",
       "cat                  4    0    0    1    0\n",
       "dog                  0    0    0    0    1\n",
       "hen                  0    0    0    1    0\n",
       "pig                  0    0    0    0    3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C2 = pd.read_excel('cohen\\'s kappa.xlsx', sheet_name = 'animals')\n",
    "C2.set_index('actual/predicted', inplace=True)\n",
    "C2 # C2 and C1 are the same, it just looks nicer when I put it in C2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Weighted Matrix \n",
    "\n",
    "An N-by-N matrix of weights, w, is calculated based on the difference between actual and predicted rating scores. The formula is as follows:  $$w_{i,j} = \\dfrac{(i-j)^2}{(N-1)^2}$$\n",
    "\n",
    "\n",
    "Under Step-2, each element is weighted. Predictions that are further away from actuals are marked harshly than predictions that are closer to actuals. However, I suddenly realized that these animals above have no obvious hierarchy in them. Therefore, it is not correct to say that predicting a cat as a bird is any better/worse off than predicting a cat as hen.\n",
    "\n",
    "**Consequently, this is a realization. Because now I start to understand why certain competitions use metrics like quadratic weighted kappa!** Consider the same example as animals just now, but instead of animals, we change to grades (can link this grading system's example to our accuracy_group in the competition). So there is an inherent order within the grades 1 - 5 such that 1 and 2 is closer than 1 and 3, 1 and 3 is closer to 1 and 4 etc. $$1 > 2 > 3 > 4 > 5$$\n",
    "\n",
    "As a result, our purpose of weighted matrix is to allocate a higher penalty score if our prediction is further away from the actual value. That is, if our grade is 2 but we predicted it as 1 (as in the second row of the matrix), then based on our formula above, we have i = 2 and j = 1 (entry $C_{2,1}$), the penalty is $$\\dfrac{(2-1)^2}{(5-1)^2}  = 0.0625$$ but if our grade is 2 and we predicted it as 4, then the penalty involved is higher $$\\dfrac{(2-4)^2}{(5-1)^2} = 0.25$$\n",
    "\n",
    "Indeed, the weight matrix helped us assign a heavier penalty to predicting 2 as 4 than 2 as 1.\n",
    "\n",
    "Lastly, we also observed that the formula will give us 0 for the diagonals of the weighted matrix. This means penalty is 0 whenever we correctly predict something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the actual vs pred grades/class\n",
    "\n",
    "actual = pd.Series([2,2,2,3,4,5,5,5,5,5]) \n",
    "pred   = pd.Series([2,2,2,3,2,1,1,1,1,3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 3, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [4, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = confusion_matrix(actual, pred); \n",
    "\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual/predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1  2  3  4  5\n",
       "actual/predicted               \n",
       "1                 0  0  0  0  0\n",
       "2                 0  3  0  0  0\n",
       "3                 0  0  1  0  0\n",
       "4                 0  1  0  0  0\n",
       "5                 4  0  1  0  0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C3 = pd.read_excel('cohen\\'s kappa.xlsx', sheet_name = 'grades')\n",
    "C3.set_index('actual/predicted', inplace=True)\n",
    "C3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate weighted matrix in python code, here is the code with reference to [Aman Arora](https://www.kaggle.com/aroraaman/quadratic-kappa-metric-explained-in-5-simple-steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.    , 0.0625, 0.25  , 0.5625, 1.    ],\n",
       "       [0.0625, 0.    , 0.0625, 0.25  , 0.5625],\n",
       "       [0.25  , 0.0625, 0.    , 0.0625, 0.25  ],\n",
       "       [0.5625, 0.25  , 0.0625, 0.    , 0.0625],\n",
       "       [1.    , 0.5625, 0.25  , 0.0625, 0.    ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted = np.zeros((5,5)) # We construct the weighted matrix starting from a zero matrix, it is like constructing a \n",
    "                           # list, we usually start from an empty list and add things inside using loops.\n",
    "\n",
    "for i in range(len(weighted)):\n",
    "    for j in range(len(weighted)):\n",
    "        weighted[i][j] = float(((i-j)**2)/16) \n",
    "        \n",
    "weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the further away from the diagonal you get, the worse off is your prediction and it will be penalized harder by a bigger weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Expected Matrix: The hardest part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuals value counts:[0. 3. 1. 1. 5.], \n",
      "Prediction value counts:[4. 4. 2. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "N=5\n",
    "act_hist=np.zeros([N])\n",
    "for item in actual: \n",
    "    act_hist[item - 1]+=1\n",
    "    \n",
    "pred_hist=np.zeros([N])\n",
    "for item in pred: \n",
    "    pred_hist[item - 1]+=1\n",
    "    \n",
    "\n",
    "print(f'Actuals value counts:{act_hist}, \\nPrediction value counts:{pred_hist}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is the most difficult to understand, especially for someone who has little statistic backgrounds (mind you when I was majoring in applied math back then, I only took **one** statistic module in my whole tenure.) Googling the idea of expected matrix is not apparently clear to me, but luckily someone pointed to me to read expected frequency of Chi-Square test and then and, there I start to slowly understand.\n",
    "\n",
    "For the purpose of better understanding, we call our actual values to be rater A and our prediction model to be rater B. We want to quantify the agreement between rater A and rater B. Here are some terminologies to get hold of first.\n",
    "\n",
    "- There are a total number of $k = 5$ classes in this example;\n",
    "- There are a total number of $n = 10$ observations in this example;\n",
    "- Define Y to be the random variable that rater A has chosen (aka our actual classes 1,2,3,4,5);\n",
    "- and $\\widehat{Y}$ be the random variable that rater $B$ has chosen (aka our predicted classes 1,2,3,4,5 by rater B)\n",
    "- $r_i$ be the i-th entry of the column vector for actual value counts shown above, $c_i$ be the i-th entry of the column vector for prediction value counts shown above.\n",
    "<br>\n",
    "\n",
    "Then the probability of rater A choosing class 2 and rater B choosing class 2 for example, is given by $$P(Y = 2 \\text{ and } \\widehat{Y} = 2)  = P(Y = 2) \\cdot P(\\widehat{Y} = 2) = 30\\% \\times 40\\%  = 12\\%$$\n",
    "\n",
    "This is under the assumption that both raters are **independent of each other**. Note that $P(Y = 2) = 30\\%$ because as we see from the actual value counts of rater $A$, there are a total of 3 class 2's and therefore the probability of Y being 2 is just the proportion. Similarly, we calculate $\\widehat{Y}$ the same way.\n",
    "\n",
    "In general, the formula of rater A choosing class i and rater B choosing (predicting) class j is given as follows: $$P(Y = i \\text{ and }  \\widehat{Y} = j) =  P(Y = i) \\times P (\\widehat{Y} = j)$$\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "Now the real question comes: On average, if you have $n$ number of points to predict, how many times (what is the frequency) would you **expect** to see rater A choose class i and rater B choose class j.\n",
    "\n",
    "To reiterate, recall that the probability of the actual class being 1 **and (super important word here, it means a joint distribution)** and the predicted class to be 1 as well is $P(Y = 1 \\text{ and }  \\widehat{Y} = 1)$, similarly, the probability of the actual class being 1 and the predicted class to be 2 is $P(Y = 1 \\text{ and }  \\widehat{Y} = 2)$. Generalizing, the probability of the actual class being $i$ and the predicted class being $j$ is the joint probability $$P(Y = i \\text{ and }  \\widehat{Y} = j)$$\n",
    "\n",
    "So the intuition lies here: based on the joint probability above, what is the expected number of times (frequency) that $Y = i$ and $\\widehat{Y} = j$ happened (this means Y is i but rater B predict $\\widehat{Y}$ as j) out of 10 times? Easy, just use $n \\times P(Y = i \\text{ and }  \\widehat{Y} = j)$. So for rater B, our prediction model, **by just using theoretical probability**, should have $n \\times P(Y = i \\text{ and }  \\widehat{Y} = j)$ for each $i,j$. But in reality, this may not be the case. Reconcile this idea with the classic coin toss example:\n",
    "\n",
    "- **Example on coin toss:** Expected frequency is defined as the number of times that we predict an event will occur based on a calculation using theoretical probabilities. You know how a coin has two sides, heads or tails? That means that the probability of the coin landing on any one side is 50% (or 1/2, because it can land on one side out of two possible sides). If you flip a coin 1,000 times, how many times would you expect to get heads? About half the time, or 500 out of the 1,000 flips. To calculate the expected frequency, all we need to do is multiply the total number of tosses (1,000) by the probability of getting a heads (1/2), and we get 1,000 * 1/2 = 500 heads. if event A has prob of p happening, and sample size of n, then the average or expected number of times that A happens is $np$. The expected frequency of heads is 500 out of 1,000 total tosses. The expected frequency is based on our knowledge of probability - we haven't actually done any coin tossing. However, if we had enough time on our hands, we could actually flip a coin 1,000 times to experimentally test our prediction. If we did this, we would be calculating the experimental frequency. The experimental frequency is defined as the number of times that we observe an event to occur when we actually perform an experiment, test, or trial in real life. If you flipped a coin 1,000 times and it landed on heads 479 times, then the experimental frequency of heads is 479.\n",
    "\n",
    "    But wait - didn't we predict the coin would land on heads 500 times? Why did it actually land on heads only 479 times? Well, the expected frequency was just that - what we expected to happen, based on our knowledge of probability. There are no guarantees when it comes to probability, what we expect to happen might differ from what actually happens. \n",
    "\n",
    "<br>\n",
    "\n",
    "Since we know $$E_{2,2} = 10 \\times P(Y = 2 \\text{ and } \\widehat{Y} = 2)  = 10 \\times P(Y = 2) \\cdot P(\\widehat{Y} = 2) = 10 \\times 30\\% \\times 40\\%  = 1.2$$\n",
    "\n",
    "This $E_{2,2}$ means that we only expect the rater A to choose 2 and rater B to choose 2 at the same time only 1.2 times out of 10 times. In other words, our predicted model classify 2 as 2 1.2 times. However, from our observations in our matrix C (confusion/histogram matrix), rater A choosing 2 and rater B choosing 2 have a frequency of 3! In other words, our predicted model classified 2 as 2 three times! So we kinda exceeded expectation for this particular configuration.\n",
    "\n",
    "$$C = \\begin{bmatrix}\n",
    "0 & 0 & 0 & 0 & 0\\\\\n",
    "0 & 3 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0\\\\\n",
    "0 & 1 & 0 & 0 & 0\\\\\n",
    "4 & 0 & 1 & 0 & 0\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Let me give you one more example, $$E_{5,2} = 10 \\times P(Y = 5 \\text{ and } \\widehat{Y} = 2) = 10 \\times P(Y = 5) \\cdot P(\\widehat{Y} = 2) = 10 \\times 50\\% \\times 40\\%  = 2$$\n",
    "\n",
    "This means that we only expect the rater A to choose 5 and rater B to choose 2 at the same time only 2 times out of 10 times! But in reality, our observations say that our rater B classified 5 as 2 zero times! \n",
    "\n",
    "\n",
    "We calculate $E_{i,j}$ given by the formula: $$E_{i,j} = n \\times P(Y = i \\text{ and }  \\widehat{Y} = j) = n \\times P(Y = i) \\times P (\\widehat{Y} = j) = n \\times \\dfrac{r_i}{n} \\times \\dfrac{c_j}{n}$$\n",
    "\n",
    "$$E = \\begin{bmatrix}\n",
    "0 & 0 & 0 & 0 & 0\\\\\n",
    "1.2 & 1.2 & 0.6 & 0 & 0 \\\\\n",
    "0.4 & 0.4 & 0.2 & 0 & 0\\\\\n",
    "0.4 & 0.4 & 0.2 & 0 & 0\\\\\n",
    "2 & 2 & 1 & 0 & 0\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Note $r_i \\times c_j$ is the $(i,j)$ entry of the outer product between the actual histogram vector of outcomes (actual value counts) and the predicted histogram vector (prediction value counts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the random chance mean here? Simple, it just means that the probability for rater A (actual) to be class i AND for rater B (predicted) to be class j is $p\\%$ (say 10%). Therefore, if we have made 100 predictions, random chance aka the theoratical probability tells us you should only have $100 \\times 10\\% = 10$ predictions to be of this configuration (rater A class i AND rater B class j)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing out the expected matrix in python\n",
    "\n",
    "So to get the expected matrix, E, is calculated assuming that there is no correlation between values.  This is calculated as the outer product between the actual histogram vector of outcomes and the predicted histogram vector, normalized such that E and C have the same sum. Note carefully below that we do not need to normalize both, we just need to normalize E to the same sum as C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , 0. , 0. ],\n",
       "       [1.2, 1.2, 0.6, 0. , 0. ],\n",
       "       [0.4, 0.4, 0.2, 0. , 0. ],\n",
       "       [0.4, 0.4, 0.2, 0. , 0. ],\n",
       "       [2. , 2. , 1. , 0. , 0. ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 3, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [4, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = np.outer(act_hist, pred_hist)/10\n",
    "\n",
    "\n",
    "E\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Step: Weighted Kappa formula\n",
    "\n",
    "From these three matrices: E, C and weighted, the quadratic weighted kappa is calculated as: \n",
    "\n",
    "$$\\kappa = 1 - \\dfrac{\\sum_{i,j}\\text{weighted}_{i,j}C_{i,j}}{\\sum_{i,j}\\text{weighted}_{i,j}E_{i,j}}$$\n",
    "\n",
    "Note that a higher value generally means your prediction model is way better than a random model, but there is no consensus on which value is really good or bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Weighted} = \\begin{bmatrix}\n",
    "0 & 0.0625 & 0.25 & 0.5625 & 1\\\\\n",
    "0.0625 & 0 & 0.0625 & 0.25 & 0.5625 \\\\\n",
    "0.25 & 0.0625 & 0 & 0.0625 & 0.25\\\\\n",
    "0.5625 & 0.25 & 0.0625 & 0 & 0.0625\\\\\n",
    "1 & 0.5625 & 0.25 & 0.0625 & 0\\\\\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notation $\\sum_{i,j}\\text{W}_{i,j}C_{i,j}$ is just $$\\sum_{i=1}^{k}\\sum_{j=1}^{k} W_{i,j} C_{i,j} = (W_{1,1}C_{1,1} + W_{1,2}C_{1,2} + ...+ W_{1,k}C_{1,k}) + (W_{2,1}C_{2,1}+...+W_{2,k}C_{2,k}) +...+(W_{k,1}C_{k,1}+...+W_{k,k}C_{k,k})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put our understanding into perspective, consider just one entry $W_{5,1}C_{5,1} = 1 \\times 4 = 4$. This roughly means that our predicted model classified class 5 as class 1 FOUR times (re: $C_{5,1} = 4$), and since class 5 is so far away from class 1, we need to **punish** this wrong prediction more than the others. And we did see that the corresponding weight $W_{5,1} = 1$ is the highest weight.\n",
    "\n",
    "Consequently, the numerator being $\\sum_{i,j}\\text{W}_{i,j}C_{i,j}$ calculates the total \"penalty cost\" for the rater A (our predicted model), and similarly, $\\sum_{i,j}\\text{W}_{i,j}E_{i,j}$ calculates the total \"penalty cost\" for the rater B (our \"expected\" model). Therefore, you can think both values (num and den) as a cost function, and the lesser the better. And kappa formula tells us, if our $\\sum_{i,j}\\text{W}_{i,j}C_{i,j}$ is significantly smaller than $\\sum_{i,j}\\text{W}_{i,j}E_{i,j}$, this will yield a very small value of $$\\dfrac{\\sum_{i,j}\\text{weighted}_{i,j}C_{i,j}}{\\sum_{i,j}\\text{weighted}_{i,j}E_{i,j}}$$ which will yield a very high kappa value - signifying a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.13924050632911378"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 1\n",
    "# apply the weights to the confusion matrix\n",
    "num = np.sum(np.multiply(weighted, C))\n",
    "# apply the weights to the histograms\n",
    "den = np.sum(np.multiply(weighted, E))\n",
    "\n",
    "kappa = 1-np.divide(num,den)\n",
    "kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.13924050632911378"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 2\n",
    "\n",
    "num=0\n",
    "den=0\n",
    "for i in range(len(weighted)):\n",
    "    for j in range(len(weighted)):\n",
    "        num+=weighted[i][j]*C[i][j]\n",
    "        den+=weighted[i][j]*E[i][j]\n",
    " \n",
    "weighted_kappa = (1 - (num/den)); weighted_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.13924050632911378"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 3: Just use sk learn library\n",
    "\n",
    "cohen_kappa_score(actual, pred, labels=None, weights= 'quadratic', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a side note that one can also use SK learn's cohen_kappa_score function calculate the quadratic weighted kappa in this competition, with weights set to quadratic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.837px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
